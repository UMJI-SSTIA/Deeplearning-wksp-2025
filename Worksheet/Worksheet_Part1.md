# Deep Learning Workshop 2025 Part A

## 0. 前言

计算机很擅长进行大量明确、重复的操作. 国际象棋中一共有 64 个格子，每方共有 6 种走法固定的棋子. 国际象棋的规则也很容易被量化. 因此 IBM 的工程师们将暴力搜索求解与相对固定的人类走法用巧妙的方式结合起来，便能用 40 年前计算机的算力击败世界顶级国际象棋棋手卡斯帕罗夫. 

假设我们有一万张图片，而我们的目标是区分每一张图片是不是猫. 

猫是一种可爱的生物. 我们并不需要有卡斯帕罗夫般的心算能力也能像吃饭、喝水一样判断一张照片是不是可爱的猫猫. 不可否认，看猫图是世界上最好的消磨时间的方式. 但是如果让你判断一万张照片，久而久之，赏心悦目的猫猫在你眼里也会变成平庸的四脚动物。我们尝试把这个任务交给计算机. 

这个过程中，计算机会遇到诸多问题：

1. 人类可以清晰地从一张图片中看到一只猫，但是计算机只能看到每个像素点的亮度；
2. 同一个摄影师从两个相近的角度拍摄了同一只猫的照片。在人类眼中，这两张照片可能并没有很大区别，但在计算机眼里，每个像素点的亮度都产生了巨大变化；
3. 同一个摄影师从相同的角度拍摄了两只猫的照片。在人类眼中，这两张照片很明显都是猫，但在计算机眼里，猫的位置上的像素点的亮度产生了巨大变化……

有时候，照片中只会出现一条猫尾巴，但人类却能笃定地说：这是只猫。就算我们成功实现了一个能够通过识别猫眼和身体来判断照片里有没有猫的程序，它也不会认为这是一只猫. 

## 1. 图像分类问题和 kNN 算法

以上这个问题是一个分类问题. 假设我们有一堆图片，并且我们人为知道这堆图片可以被分成哪几类，那么我们的目标就是实现一个在接受一张图片后快速判断这个图片属于哪一类. 手写数字识别便属于这一问题. 

### 1.1 常用数据集

深度学习需要大量训练数据。每个数据点都应形如 `(image, label)`，其中`image` 为图像本身，而 `label` 为图像对应的分类. 对于初学者来说，最大的门槛就是获取这一数据. 所幸，已经有很多人为不同情景的模型训练收集了大量被分好类的图片数据，我们可以直接使用它们训练自己的模型。以下是我们会涉及到的两个数据集：

- MNIST
    - 50000 张训练图片 + 10000 张测试图片；
    - 每张图片都是 28x28 的灰度图像，内容是手写数字；
    - 每张照片对应的 `label`，表示图像中的数字是 0~9 中的哪一个.
- CIFAR-10
    - 50000 张训练图片 + 10000 张测试图片；
    - 每张图片都是 32x32 的 RGB 三通道图像，内容是生活中常见的十种动物或载具；
    - 每张照片对应的 `label`，表示图像中的主要物体是哪一类动物或载具.

人类能快速判断一张照片属于哪一类，是因为人学习过什么是猫. 我们尝试在计算机上复现这个学习过程. 

### 1.2 k-Nearest Neighbor

我们以 CIFAR-10 为例，考虑如何实现一个靠谱的图像分类算法. 

#### 1.2.1 问题简化

我们先考虑一个更简单的问题. 有一个被红蓝两种颜色涂满的二维平面，但是我们并不知道红色和蓝色的边界在哪. 但是我们知道这个平面上有很多点，我们也知道每个点所在的位置上平面被涂的颜色是什么. 我们希望能尽可能准确地猜测平面上任意一个点（在图中用绿色虚线轮廓的点表示）所对应的颜色是什么. 

![](../img/Part1/1_2_1.png)

一个很直观的想法是根据距离这个点最近的 $k$ 个邻居的颜色来决定这个点对应的颜色. 当 $k=5$ 时，我们发现距离未知点最近的 $5$ 个点中，有 $3$ 个红点和 $2$ 个蓝点。那么我们便预测这个点是红色的. 这便是 k-Nearest Neighbor (kNN) 算法.

#### 1.2.2 kNN

回到 CIFAR-10 数据集。CIFAR-10 的每个图片都由 32x32 个 RGB 三通道的像素组成，并且有 10 种可能的 `label`。把图片上每个像素点上每个通道的明度都当作这个图片所对应数据点在某一维上的坐标，我们便可以把每个图片映射到一个高维空间的点上. 于是我们改编一下上述问题：

有一个被 $10$ 种颜色涂满的，$32\times32\times3=3072$ 维的高维空间，但是我们并不知道这 $10$ 种颜色的边界在哪. 但是我们知道这个空间上有 $50000$ 个点，我们也知道每个点所在的位置上的空间被涂的颜色是什么. 我们希望能尽可能准确地猜测这个高维空间中的任意一个点所对应的颜色是什么. 

在使用 kNN 算法之前，我们需要先解决两个问题：

我们需要先定义 $3072$ 维的空间中两个点的距离. 假如$I_i$ 代表第 $i$ 张图片的数据点，$I_{i,p}$ 代表这个数据点在第 $p$ 维上的距离，拓展二维空间中欧氏距离的定义，可以得到
$$d(I_1, I_2) = \sqrt{\sum_{p=1}^{3072}(I_{1, p}-I_{2,p})^2}.$$

其次，考虑到取 $k$ 个最近的邻居的众数可能会出现平局的情况，我们需要一个能够打破平局的规则. 当平局出现时，可以从最高票数的几个标签中选择一个距离最近的点.

#### 1.2.3 超参数 Hyperparameters

超参数指在模型训练之前就已经人为确认好的参数. 在 kNN 算法中，这个 $k$ 便是一个超参数. 我们考虑怎样才能选择最优的 $k$.

1. 采用在训练数据上表现最好的 $k$
    - 这种做法等价于直接选择 $k=1$. 
2. 将已有数据分成两部分：90% 用于训练，剩下的 10% 用于测试；选择在测试数据上表现最好的 $k$
    - 我们无法确认这样选择的 $k$ 在新数据上的表现如何.

我们在调试超参数时需要注意数据污染问题: 我们不能让测试数据对超参数的设置产生影响.

3. 将已有数据分成三部分：大部分用于训练，一小部分用于验证，另一小部分用于测试；选择在验证集上表现最好的 $k$，再在测试集上测试算法的准确率.

#### 1.2.4 反思

这个方法很蠢.

kNN 模型无需训练，但设 $N$ 为训练数据集的大小，$d$ 为每个数据点的维数，使用 kNN 预测一个测试图片的标签的时间复杂度是 $O(dN)$ 的么在 $N=50000, d=3072$ 时，测试一张照片很慢. 实际上，我们可以忍受训练模型时的高时间复杂度，但要求使用这个模型来预测未知数据的标签尽可能高效.

其次，对每个像素的每个通道求欧式距离这个操作并没有什么直观意义.

值得一提的是，对卷积神经网络 (ConvNet) 处理后的多维空间中的数据点使用 kNN 算法效果很好. 这一算法会在 Part 2 中提及.

## 2. 线性分类器 Linear Classifier

我们也可以把每个图片看作一个 $3072$ 维的向量。想到可以使用矩阵乘法来对这个向量进行线性变换.

我们的模型可以抽象成一个函数 $f: (x,W)\mapsto W\cdot x$. 其中，$x$ 是 $3072$ 维的图片向量，$W$ 是 $10\times3072$ 的参数矩阵，$W\cdot x$ 的结果是一个 $10$ 维的向量，其中第 $i$ 维的大小代表 $W$ 对 $x$ 属于第 $i$ 个标签的评价. 

### 2.1 损失函数 Loss Function

工欲善其事，必先利其器. 在考虑怎么获得优秀的参数矩阵 $W$ 之前，我们可以先考虑怎样评定一个 $W$ 是否优秀. 

对于某个图片的向量 $x$，令 $s=f(x,W)$ 为其评分向量. 我们取评分最高的那一个标签作为对这个图片的预测. 

#### 2.1.1 Softmax

#### 2.1.2 交叉熵损失函数 Cross-Entropy Loss

### 2.2 对 $W$ 进行优化

#### 2.2.1 矩阵的梯度矩阵

#### 2.2.2 梯度下降 Gradient Descent

#### 2.2.3 随机梯度下降 Stochasitc Gradient Descnet

#### 2.2.4 SGD + 动量方法

#### 2.2.5 RMSProp + 动量方法

## 3. 神经网络

### 3.1 激活函数 Activation Function

#### 3.1.1 引入非线性因素

#### 3.1.2 ReLU 函数

### 3.2 反向传递 Backpropagation